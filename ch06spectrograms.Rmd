# Spectrograms {#ch-spectrograms}

*Chapter keywords*: spectrogram, center frequency, bandwidth, broadband, narrowband, detail, smearing, formant, amplitude, frequency, time, component, harmonic, glottal pulse.  

## Introduction {#sec:spectrogram-intro}

As we saw, a spectrum (§\@ref(sec:spectrum)) shows the various frequency components of a complex signal, such as the formants of a vowel (§\@ref(sec:formants)). However, a spectrum either shows the frequency composition of an entire digital sound, or it shows the frequency composition of a brief 'slice' or frame or window of that sound (box \@ref(sec:spectrum)). 

In order to track spectral changes over time, we need a series of spectral slices, measured at fixed intervals. Thus we wish to depict three dimensions: time, amplitude, and frequency. This most important visualisation in speech analysis is called a **spectrogram**. As in an oscillogram, *time* is shown along the horizontal axis. Like in a spectrum, but rotated by 90°, *frequency* is shown along the vertical axis. *Amplitude* is shown in the degree of blackness (or in coloring). 
The example spectrogram in Figure \@ref(fig:merel-spectrogram) visualizes a blackbird song, showing the amplitudes (blackness) of the frequency components (vertically), varying over time (horizontally). 

```{r merel-spectrogram, echo=FALSE, fig.cap="Spectrogram of a brief part of song by a blackbird.", fig.align="center"}
knitr::include_graphics("figures/merel-spectrogram.png")
```

In this spectrogram you see an initial steeply falling 'chirp' sound, followed by three repetitions of a two-tone 'syllable', against a background of other birdsong. 

Spectrograms used to be made by means of a special device, a sonagraph or spectrograph, which worked by means of a bandpass filter (Fig.\@ref(fig:bandpassfilter)). This bandpass filter was initially set to a low *center frequency*, then applied to the sound recording, and the resulting output amplitude of the filter was printed as varying degrees of blackness, resulting in a single horizontal 'line' of the figure. Then the frequency band of the filter was increased slightly, to produce the next 'line' of the figure. This was repeated across the entire range of frequencies^[Thus a spectrograph required several minutes to produce a single spectrogram.]. Moreover, a spectrograph used to have two fixed settings for the *bandwidth* of the band-pass filter (§\@ref(sec:filterbandwidth)): 260 Hz for so-called broadband spectrograms, and 43 Hz for narrowband spectrograms, respectively. (Nowadays, in digital speech analysis, bandwidth is controlled indirectly, via the length of the window for spectral analysis, see §\@ref(sec:spectralslice) and see below).

## Broadband spectrogram

In a broad-band spectrogram, as in Fig.\@ref(fig:speech-word-spectrogram-broad), the bandwidth used in the spectral analysis is relatively wide (by convention, 260 Hz).

```{r speech-word-spectrogram-broad, echo=FALSE, fig.cap="Oscillogram, broad-band spectrum at 0.210 s, and broad-band spectrogram of the word *speech*.", fig.align="center"}
knitr::include_graphics("figures/speech_word_spectrogram_5ms.png")
```

The wide bandwidth results in less detail (more smearing) in the frequency dimension, while allowing more detail in the time dimension. We can see temporal events in great detail, such as individual periods of voiced parts, and noise bursts in plosive or affricate consonants. On the other hand, frequencies are blurred or smeared. This makes it easier, however, to see formants (§\@ref(sec:formants)) in the vowels, and to see other "broad" spectral properties in the consonants.   

## Narrowband spectrogram

In a narrow-band spectrogram, as in Fig.\@ref(fig:speech-word-spectrogram-narrow), the bandwidth used in the spectral analysis is relatively narrow (by convention, 43 Hz).

```{r speech-word-spectrogram-narrow, echo=FALSE, fig.cap="Oscillogram, narrow-band spectrum at 0.210 s, and narrow-band spectrogram of the word *speech*.", fig.align="center"}
knitr::include_graphics("figures/speech_word_spectrogram_30ms.png")
```

The narrow bandwidth results in more detail in the frequency dimension, while allowing less detail (more smearing) in the time dimension. We can see frequencies in great detail, such as individual harmonics in voiced parts. On the other hand, brief temporal events such as noise bursts are blurred or smeared. 

::: {#box-praatspectrogram .praatbox}

## How to make a spectrogram {#sec:howto-spectrogram}

There are two ways to create a spectrogram of a sound recording: either directly, or by means of the SoundEditor. 

### to Spectrogram directly

- Select an input Sound object in the `Praat` Objects window. Then choose `Analyse spectum >`, then `To Spectrogram...`. 

- The parameter `Window length` determines the filter bandwidth used to create the spectrogram. For a broadband spectrogram, choose $0.005\ \textrm{s}$; for a narrowband spectrogram, choose $0.030\ \textrm{s}$. 
For the spectrogram of birdsong in Fig.\@ref(fig:merel-spectrogram), an intermediate value of 0.015 s was used.\
Set `Window shape` to `Gaussian`.\
Leave other arguments at their default (standard) values. Click `OK`.

- The resulting Spectrogram object is again added at the bottom of the list of objects. 

- You may `Draw > Paint...` the spectrogram. Specify the time and frequency range, as well as the dynamic range (of amplitude in dB, between darkest and lightest colour).\
The `Pre-emphasis` slope helps in discerning visual details in the higher frequencies, as explained in §\@ref(sec:emphasisfilters) and §\@ref(sec:vowelproduction); the default value of $+6$ dB per octave works well in most situations. 

- Remember to `Save` the Spectrogram object if you wish. 

### from SoundEditor {#sec:spectrogramsoundeditor}

This method is similar to the spectral analysis described in §\@ref(sec:spectralslice). Using this method, your spectrogram in the SoundEditor is immediately updated if you change (`Apply`) values for the analysis parameters (which may be convenient), but extracting and saving the Spectrogram requires some extra work. 

- In the `Praat` object window, select a Sound object.

- Next, in the `Praat` object window, choose `View & Edit`. This will open a so-called SoundEditor window, with the oscillogram as its main feature. 

> TODO crossref SoundEditor

- In the SoundEditor window, go to `Spectrogram...` and then `Spectrogram settings`. 

- The parameter `Window length` determines the filter bandwidth used to create the spectrogram. For a broadband spectrogram, choose $0.005\ \textrm{s}$; for a narrowband spectrogram, choose $0.030\ \textrm{s}$. 
For the spectrogram of birdsong in Fig.\@ref(fig:merel-spectrogram), an intermediate value of 0.015 s was used.\
Set the `Dynamic range` (of amplitude in dB) between darkest and lightest colour to some value between $40$ and $55$ dB (try different values by using `Apply`, and notice the differences in the resulting spectrogram). 
Leave other arguments at their default (standard) values. Click `OK`.

- Make sure that you can see the Spectrogram in the SoundEditor, by selecting the option `Spectrogram > View Spectrogram`. This setting is saved from session to session, so you may have to switch `on` the spectrogram view.  

- If you are happy with the spectrogram in the SoundEditor panel, you can then choose `Spectrogram > Paint visible spectrogram...` in order to draw that spectrogram in the Picture window. 

- You can also `Extract` and then `Save` the spectrogram from the SoundEditor in order to save it as an object in the Objects window. 

:::

## How to read a spectrogram {#sec:readspectrogram}

(with Clizia Welker)

::: {#box-spectrogram .warningbox}

This section intends to provide some hints on how to read a spectrogram. The skill of reading a spectrogram is highly useful whenever you need to *annotate* a speech recording, that is, dividing or segmenting it into syllables or phones, and/or transcribing (labeling) the words or sounds spoken. For more detailed explanations, please refer to your textbooks on phonetics (for recommended textbooks see §\@ref(sec:textbooks)), and see Chapter \@ref(ch-annotation) on annotating speech. Also consult the valuable instructions and background on [how to read a spectrogram](https://home.cc.umanitoba.ca/~robh/howto.html) by Rob Hagiwara.  

::: 

While by observing an oscillogram it is only possible to identify broad phonetic classes, the spectrogram provides us with sufficient information to determine the phones. It is possible to deduce the phones (with good chances of success) by exploiting information about

- the frequency values of the formants,

- the energy pattern throughout the spectrogram,

- the formant transitions (from vowel to consonants and from consonants to vowels).

Except for the formant transitions (see below), these features may be found in a spectrum too, but spectrograms allow us to inspect these features over time. 

In order to read a spectrogram, we need to remember that:

- the blacker regions are frequency regions with a high degree of energy (§\@ref(sec:spectrogram-intro)),

- the black band at the bottom of the spectrogram displays the $f_0$ in voiced parts; it may be difficult to distinguish fundamental $f_0$ from formant F1 (especially in closed vowels, which have a low F1 close to $f_0$ ^[If speaking or singing at high fundamental $f_0$, the $f_0$ may even be higher than F1, thus rendering F1 inaudible.]),

- vowels are characterised by a clear formant pattern (§\@ref(sec:formants)), visible as horizontal black bands,

- consonants (especially voiceless ones) do not have a clear formant pattern, but the distribution of energy throughout the spectrum helps us identifying them,

- the vertical bands at regular time intervals in the broad-band spectrogram correspond to the glottal pulses (cycles of opening and closing of the vocal folds).

**Vowels** may be distinguished through their formant values, especially through F1, F2 and F3; consult a vowel diagram in your textbook. 

**Dipthongs** (such as in the Dutch words *bij*, *bui* and *bouw*) are composed of two different vowel sounds, with a gradual movement of the formants from their initial to final frequency values. 

For **voiced consonants** in a CV context, formant frequencies change relatively rapidly. The *F2* value in the vowel from which the formant travels in this formant transition is often called the 'F2 locus', and this locus is correlated with the place of articulation of the consonant. The F2 transition is also due to the fact that acoustic resonators (tube sections) are uncoupled at the moment of closure or frication, but become coupled as the mouth opens.
For labial consonants the F2 locus is around 700 Hz, for alveolar consonants it is around 1800 Hz, and for velar consonants it is around 2700 Hz.   
In CV context, rapid F1 transitions are related to the degree of jaw opening, with F1 increasing from zero to its vowel value during opening of the mouth.   
In VC contexts we see similar patterns as in CV contexts, but reversed in time.

While **voiceless consonants** are not characterised by formants (even in an intervocalic context), their place of articulation may be assessed by looking at which frequency regions display a high concentration of energy. Moreover, in CV context, the rapid F2 transitions may seem to travel from the same F2 locus as for corresponding voiced consonants with the same place of articulation, albeit with formants less visible in transitions involving voiceless consonants.

The distinction between voiced and voiceless plosive consonants largely depends on the **voice onset time (VOT)**, "defined by the time elapsed between the release of the stop consonant constriction (sometimes called the “burst”) and the onset of periodicity in the following voiced segment" [@Rubin_2022]. The release or burst is visible as a brief noise segment; the following voiced segment typically has initial formant transitions (see above), and visible glottal pulses or visible harmonics (see above). 

In producing **alveolar** consonants, the vocal tract is divided into two smaller cavities: a large back cavity, and a small front cavity between the alveolar obstruction and the outside air. Due to its small size, the front cavity yields resonances in the higher frequency regions, as we can see in the initial consonant [s] in Fig.\@ref(fig:speech-word-spectrogram-broad). In **palatal** consonants (such as the final consonant in the same spectrogram), the place of artiulation is more backward, the front cavity is larger, and the so-called 'spectral centre of gravity' in the resulting consonant is correspondingly lower. 

**Nasal and lateral** consonants are phonetically complex. They resemble vowels, but the vocal tract has additional cavities during the production of these sounds: for nasals, the nasal cavity, and for laterals, additional cavities under and aside of the tongue. The resulting sound has resonances due to these cavities, as well as anti-resonances due to the acoustic *coupling* between branching cavities. 

For more tips and tricks and background about how to identify speech segments in a spectrogram, please consult your textbooks on phonetics, as well as the resources mentioned in the first paragraph of this section. 

## More about using the SoundEditor {sec:soundeditor3}

In several sections above we have encountered the SoundEditor: in §\@ref(sec:praatsoundeditor) and in §\@ref(sec:spectrogramsoundeditor). Please re-read those sections before you continue. 
The powerful SoundEditor provides you with lots of information about the sound recording: oscillogram, spectrogram, formant analysis, as well as prosodic information (which will be discussed further in Chapter \@ref(ch-prosody)). 
Here we will provide some additional instructions not yet covered in the sections above. 

::: {#box-soundeditor-3 .praatbox}

- Select an input Sound object in the `Praat` Objects window. 

- Choose `View & Edit`.
This will open a **SoundEditor** window.
Figure \@ref(fig:window-soundeditor-3) shows an example of a SoundEditor, displaying the fragment *why is it so good* spoken by a female speaker of English; the single word *why* is highlighted. 

```{r window-soundeditor-3, echo=FALSE, fig.cap="SoundEditor window, showing oscillogram and spectrogram of the fragment *why is it so good...*, with the word *why* highlighted.", fig.align="center"}
knitr::include_graphics("figures/s321f1-1_informal_fragment_SoundEditor20250203.png")
```

::: {#box-windowsfile-details .smallprintbox}

> TODO REVISE

The SoundEditor in Fig.\@ref(fig:window-soundeditor) shows a fragment of speech, taken from the audio file named  `10-18-17_Council_SLASH_10-18-17_Council_DOT_HD_DOT_mp3_00285.flac` from the *Peoples Speech* corpus at <https://huggingface.co/datasets/MLCommons/peoples_speech>. For details about that corpus, see @Galvez_Diamos_Ciro_Cerón_Achorn_Gopi_Kanter_Lam_Mazumder_Reddi_2021.

:::

The SoundEditor contains a lot of information! In the top panel you always see an oscillogram (§\@ref(sec:oscillogram)). Below, there may be additional and overlapping visualisations of the Spectrogram (Ch.\@ref(ch-spectrograms)), Pitch, Intensity, Formants (§\@ref(sec:formants)), and/or voice Pulses. These additional visualisations will be discussed later in this tutorial guide; for now, you may switch them `off` by choosing the appropriate buttons in the top of the SoundEditor window, and then unselecting the `Show` option. 

- In the SoundEditor window, you can **select** a part of the recording with your mouse. The selected area is marked in pink in the oscillogram panel of the SoundEditor window, as shown in Fig.\@ref(fig:window-soundeditor). 

- You can **play back** the selected part, or the parts before/after it, by clicking the appropriate buttons (labeled with the durations of those parts). For more information about audio playback from `Praat`, consult §\@ref(sec:playback) above.

- In the SoundEditor window, you can use the buttons in the lower left corner to **zoom** `in`, `out`, to zoom out to the entire sound (`all`), or to zoom to the `sel`ected part. 
- You can also select a part of the recording by specifying the start and end times explicitly: choose `Time > Select...` and enter the start and end times. 

- By convention, the selected part should begin and end at **positive zero crossings** (where the signal changes from negative to positive; see §\@ref(sec:fades) below). You can find these precise places as follows (disregarding shortcuts in `Praat`):
  - put the cursor in the approximate area where the boundary should be located;
  - choose `Sound > Move cursor to nearest zero crossing`;
  - ask `Praat` to report the cursor location in its Info window: `Time : Get cursor`, and note this time;
  - do this for both start and end of the selection part;
  - use these noted times to set the selection part as described above. 

- In this way, the word *window* was selected in the SoundEditor in Fig.\@ref(fig:window-soundeditor). 

- To **save** the selected part as a separate audio file: in the SoundEditor, choose `File > Save selected sound as WAV file...`. 
Provide the appropriate folder and file name, and click `OK`. 

- You may also **extract** the selected part into a new Sound object in `Praat`. In the SoundEditor window, choose `Sound > Extract selected sound (preserve times)` if you wish to maintain the same times as in your source recording: the new Sound object will have a starting time equal to the starting time of the selection in the source recording. If you want your new Sound to start at zero, then choose `Sound > Extract selected sound (time from 0)`.  

- The new Sound object may need a fade-in and fade-out (see §\@ref(sec:fades) below). 

- Remember to save this new Sound object (see §\@ref(sec:praatsave)) if you wish to keep it. 

:::
